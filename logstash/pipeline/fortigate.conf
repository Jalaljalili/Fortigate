input {
  file {
    path => "/usr/share/logstash/fortigate-logs/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
  # The log line is a series of key=value pairs, let's use the kv filter directly.
  kv {
    source => "message"
    field_split => " "
    value_split => "="
    # The kv filter is smart enough to handle quoted values.
  }

  # Parse the date and time from the log and set it as the timestamp.
  date {
    match => ["date", "YYYY-MM-dd"]
    # We combine date and time fields into a temporary field to parse.
    target => "@timestamp"
    add_field => { "temp_datetime" => "%{date} %{time}" }
  }

  # Use the date filter again to correctly parse the full timestamp.
  date {
    match => ["temp_datetime", "yyyy-MM-dd HH:mm:ss"]
    target => "@timestamp"
  }

  # Optional: Remove temporary or unneeded fields.
  mutate {
    remove_field => ["temp_datetime", "date", "time"]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "fortigate-logs-%{+YYYY.MM.dd}"
  }
  stdout { codec => rubydebug }
}
